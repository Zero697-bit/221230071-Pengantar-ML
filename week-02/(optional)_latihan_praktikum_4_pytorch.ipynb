{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBMNEUL4hgUSupjTr3+Nau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zero697-bit/221230071-Pengantar-ML/blob/main/week-02/(optional)_latihan_praktikum_4_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏋️ LATIHAN 4: OPERASI PYTORCH UNTUK DEEP LEARNING ##"
      ],
      "metadata": {
        "id": "8PK9B9CLw8Qm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " TENSOR OPERATIONS FOR NEURAL NETWORKS"
      ],
      "metadata": {
        "id": "bGVPiRvcw_Zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "2HnBLASn2FZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# ==========================================\n",
        "# TASK: Implementasi Operasi Dasar Neural Networks dengan PyTorch\n",
        "# ==========================================\n",
        "\n",
        "# Simulasi batch data: 32 samples, 10 features\n",
        "batch_size, n_features = 32, 10\n",
        "X = torch.randn(batch_size, n_features)   # input tensor\n",
        "weights = torch.randn(n_features, 1)      # bobot linear\n",
        "bias = torch.randn(1)                     # bias\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# TASK 1: Implementasi linear layer manual\n",
        "# Rumus: y = XW + b\n",
        "# ------------------------------------------------------\n",
        "def linear_layer(X, W, b):\n",
        "    return torch.matmul(X, W) + b   # (32,10) x (10,1) = (32,1)\n",
        "\n",
        "output = linear_layer(X, weights, bias)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# TASK 2: Implementasi ReLU activation function\n",
        "# ReLU(x) = max(0, x)\n",
        "# ------------------------------------------------------\n",
        "def relu_activation(tensor):\n",
        "    return torch.maximum(tensor, torch.tensor(0.0))\n",
        "\n",
        "activated = relu_activation(output)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# TASK 3: Batch Normalization sederhana\n",
        "# Formula: (x - mean) / (std + epsilon)\n",
        "# Normalisasi dilakukan per fitur di dalam batch\n",
        "# ------------------------------------------------------\n",
        "def simple_batch_norm(tensor, epsilon=1e-5):\n",
        "    mean = tensor.mean(dim=0, keepdim=True)  # mean per fitur\n",
        "    std = tensor.std(dim=0, keepdim=True)    # std per fitur\n",
        "    return (tensor - mean) / (std + epsilon)\n",
        "\n",
        "normalized = simple_batch_norm(X)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# TASK 4: One-hot encoding manual\n",
        "# Input: tensor label (n,), Output: (n, num_classes)\n",
        "# ------------------------------------------------------\n",
        "def one_hot_pytorch(labels, num_classes):\n",
        "    one_hot = torch.zeros(labels.size(0), num_classes)\n",
        "    one_hot[torch.arange(labels.size(0)), labels] = 1\n",
        "    return one_hot\n",
        "\n",
        "labels = torch.randint(0, 3, (10,))   # 10 sample label, kelas 0-2\n",
        "one_hot = one_hot_pytorch(labels, num_classes=3)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# TEST ASSERTIONS\n",
        "# ------------------------------------------------------\n",
        "assert output.shape == (batch_size, 1), \"Linear output shape incorrect\"\n",
        "assert torch.all(activated >= 0), \"ReLU should be >= 0\"\n",
        "assert normalized.shape == X.shape, \"Batch norm should preserve shape\"\n",
        "assert one_hot.shape == (10, 3), \"One-hot shape incorrect\"\n",
        "print(\"✅ PyTorch operations completed\")\n",
        "\n",
        "# ==========================================\n",
        "# BONUS: ADVANCED TENSOR OPERATIONS\n",
        "# ==========================================\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# TASK: Matrix Multiplication dari Prinsip Dasar\n",
        "# Implementasi manual tanpa torch.matmul\n",
        "# ------------------------------------------------------\n",
        "def manual_matrix_multiply(A, B):\n",
        "    rows_A, cols_A = A.shape\n",
        "    rows_B, cols_B = B.shape\n",
        "    assert cols_A == rows_B, \"Ukuran matriks tidak cocok\"\n",
        "\n",
        "    result = torch.zeros(rows_A, cols_B)\n",
        "    for i in range(rows_A):\n",
        "        for j in range(cols_B):\n",
        "            for k in range(cols_A):\n",
        "                result[i, j] += A[i, k] * B[k, j]\n",
        "    return result\n",
        "\n",
        "# Test dengan matriks kecil\n",
        "A = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
        "B = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
        "\n",
        "manual_result = manual_matrix_multiply(A, B)\n",
        "torch_result = torch.matmul(A, B)\n",
        "\n",
        "assert torch.allclose(manual_result, torch_result)\n"
      ],
      "metadata": {
        "id": "OqNJtfBhxRae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}